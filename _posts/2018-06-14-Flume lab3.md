---
title: Flume lab3
layout: post
tags: Hadoop
categories: ''
---
# Flume lab3

> 目标:
> > 分布式日志采集，将一台服务器的日志收集到另一台服务器进行处理；理解avro source,avro sink

#### 参考资料
##### [Apache Flume官网](http://flume.apache.org/FlumeUserGuide.html)


#### 前置条件：  
>> 已经安装了flume，配置了环境变量
>> 已经JDK，配置了环境变量
>> 明白flume的基本架构，明白agent
<!--more-->
#### 环境说明
>> 两台服务器，一台产生日志，一台收集日志

Flume基本概念图    

![UserGuide_image00](http://p1vuoao0b.bkt.clouddn.com/JekyllWriter/UserGuide_image00.png)


avro source 官网解释  

![TIM截图20180614020022](http://p1vuoao0b.bkt.clouddn.com/JekyllWriter/TIM截图20180614020022.png)  

Example for agent named a1:

		a1.sources = r1
		a1.channels = c1
		a1.sources.r1.type = avro
		a1.sources.r1.channels = c1
		a1.sources.r1.bind = 0.0.0.0
		a1.sources.r1.port = 4141

avro sink 官网解释  
![TIM截图20180614020341](http://p1vuoao0b.bkt.clouddn.com/JekyllWriter/TIM截图20180614020341.png)

Example for agent named a1:  

		a1.channels = c1
		a1.sinks = k1
		a1.sinks.k1.type = avro
		a1.sinks.k1.channel = c1
		a1.sinks.k1.hostname = 10.10.10.10
		a1.sinks.k1.port = 4545




收集日志的服务器cdh3配置文件如下  




		{% highlight javascript %}
		# example.conf: A single-node Flume configuration

		# Name the components on this agent
		exex-memory-avro.sources = r1
		exex-memory-avro.sinks = k1
		exex-memory-avro.channels = c1
		
		# Describe/configure the source
		exex-memory-avro.sources.r1.type = exec
		exex-memory-avro.sources.r1.command = tail -F /home/ccc/data.log
		exex-memory-avro.sources.r1.shell=/bin/sh -c
		
		# Describe the sink
		exex-memory-avro.sinks.k1.type = avro
		exex-memory-avro.sinks.k1.hostname=cdh2
		exex-memory-avro.sinks.k1.port=44444
		
		# Use a channel which buffers events in memory
		exex-memory-avro.channels.c1.type = memory
		
		# Bind the source and sink to the channel
		exex-memory-avro.sources.r1.channels = c1
		exex-memory-avro.sinks.k1.channel = c1
		{% endhighlight javascript %}


接受处理服务器cdh2配置如下：


		{% highlight javascript %}
		
		# example.conf: A single-node Flume configuration
		
		# Name the components on this agent
		avro-memory-logger.sources = r1
		avro-memory-logger.sinks = k1
		avro-memory-logger.channels = c1
		
		# Describe/configure the source
		avro-memory-logger.sources.r1.type = avro
		avro-memory-logger.sources.r1.bind = cdh3
		avro-memory-logger.sources.r1.port=44444
		
		# Describe the sink
		avro-memory-logger.sinks.k1.type = logger
		
		
		# Use a channel which buffers events in memory
		avro-memory-logger.channels.c1.type = memory
		
		# Bind the source and sink to the channel
		avro-memory-logger.sources.r1.channels = c1
		avro-memory-logger.sinks.k1.channel = c1 
		
		{% endhighlight javascript %}
		
 

先启动cdh2的接受程序：  

	flume-ng agent --name avro-memory-logger --conf /etc/flume-ng/conf -f /home/ccc/avro-memory-logger.conf -Dflume.root.logger=INFO,console

然后启动cdh3的监控程序：  
		
	flume-ng agent --name exex-memory-avro --conf /etc/flume-ng/conf -f /home/ccc/exex-memory-avro.conf  -Dflume.root.logger=INFO,console
	
往监控文件写入东西：

	[root@cdh3 ccc]# echo "td">data.log
	[root@cdh3 ccc]# echo "td">data.log
	[root@cdh3 ccc]# echo "hello world">data.log
	[root@cdh3 ccc]# echo "hello ccc teradata">data.log
	[root@cdh3 ccc]# echo "hello ccc teradata">data.log
	
cdh2服务其中文件监控信息：

![TIM截图20180614122140](http://p1vuoao0b.bkt.clouddn.com/JekyllWriter/TIM截图20180614122140.png)

自此flume学习完毕，只要明白flume基本架构agent(source,channel,sink)等等配置就行了，然后就可以多个agent组合使用，例如本案例中就是两个agent的组合使用，接下来我们学习kafka和spark Streaming搭建日志分析为例的一整套流程。